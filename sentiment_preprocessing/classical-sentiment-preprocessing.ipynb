{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e3d9e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfb1f42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "review       0\n",
      "sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Download the English model for spaCy\n",
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "\n",
    "# Load Dataset\n",
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "print(df.head())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0a4fb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  \\\n",
      "0  One of the other reviewers has mentioned that ...   \n",
      "1  A wonderful little production. <br /><br />The...   \n",
      "2  I thought this was a wonderful way to spend ti...   \n",
      "3  Basically there's a family where a little boy ...   \n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
      "\n",
      "                                   preprocessed_text  \n",
      "0  reviewer mention watch 1 Oz episode hook right...  \n",
      "1  wonderful little production < br /><br />the f...  \n",
      "2  think wonderful way spend time hot summer week...  \n",
      "3  basically family little boy Jake think zombie ...  \n",
      "4  Petter Mattei love Time money visually stunnin...  \n"
     ]
    }
   ],
   "source": [
    "# Disable componenents to speed up processing and focus on tokenization and lemmatization\n",
    "nlp = spacy.load(\"en_core_web_sm\",disable=[\"parser\", \"ner\"])\n",
    "\n",
    "# Process reviews efficiently using streaming (generator) to avoid memory overflow on large datasets\n",
    "def preprocess_dataset(texts):\n",
    "    preprocessed_text = []\n",
    "    # nlp.pipe processes texts as a stream and is much faster than applying nlp to each text individually\n",
    "    for doc in nlp.pipe(texts, batch_size=1000):\n",
    "        # Extract lemmas for non-stop, non-punct tokens\n",
    "        tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "        preprocessed_text.append(' '.join(tokens))\n",
    "    return preprocessed_text\n",
    "            \n",
    "df['preprocessed_text'] = preprocess_dataset(df['review'])\n",
    "\n",
    "# Display original and preprocessed text for the first few reviews to verify preprocessing\n",
    "print(df[['review', 'preprocessed_text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5862ef98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Vocabulary & Vectorizers\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Initialize vectorizers with n-gram support\n",
    "bow_vectorizer = CountVectorizer(ngram_range=(1, 2), min_df=5, max_features=1000) # ngram_range=(1,2) means unigrams + bigrams\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=5, max_features=1000) # min_df=5 ignores terms that appear in less than 5 documents (removes noise)\n",
    "\n",
    "# Save vectorizers to a pickle file\n",
    "with open('vectorizers.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'bow_vectorizer': bow_vectorizer,\n",
    "        'tfidf_vectorizer': tfidf_vectorizer\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4165d49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 40000\n",
      "Test set size: 10000\n",
      "BoW Matrix Shape (train): (40000, 1000)\n",
      "TF-IDF Matrix Shape (train): (40000, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Vectorization Phase\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Encode labels first (positive = 1, negative = 0)\n",
    "df['label'] = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "\n",
    "# Split data before vectorization to prevent data leakage\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    df['preprocessed_text'], \n",
    "    df['label'], \n",
    "    test_size=0.2, \n",
    "    stratify=df['label'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit vectorizers on training data only, then transform both sets\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train_text)\n",
    "X_test_bow = bow_vectorizer.transform(X_test_text)\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_text)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_text)\n",
    "\n",
    "print(f\"Training set size: {len(X_train_text)}\")\n",
    "print(f\"Test set size: {len(X_test_text)}\")\n",
    "print(f\"BoW Matrix Shape (train): {X_train_bow.shape}\")\n",
    "print(f\"TF-IDF Matrix Shape (train): {X_train_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f841783e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86      5000\n",
      "           1       0.85      0.87      0.86      5000\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "[[4254  746]\n",
      " [ 655 4345]]\n",
      "TF-IDF Naive Bayes Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83      5000\n",
      "           1       0.82      0.85      0.83      5000\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n",
      "[[4057  943]\n",
      " [ 748 4252]]\n",
      "BoW Naive Bayes Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      5000\n",
      "           1       0.82      0.84      0.83      5000\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n",
      "[[4059  941]\n",
      " [ 793 4207]]\n",
      "BoW Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86      5000\n",
      "           1       0.85      0.87      0.86      5000\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "[[4253  747]\n",
      " [ 650 4350]]\n"
     ]
    }
   ],
   "source": [
    "# Training Pipeline with Cross-Validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "\n",
    "# Set up Stratified K-Fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize model with regularization to prevent overfitting\n",
    "model_tfidf = LogisticRegressionCV(\n",
    "    max_iter=1000, \n",
    "    Cs=20,  # Range of inverse regularization strengths to try\n",
    "    solver='saga',  # Fast for large datasets\n",
    "    n_jobs=-1,  # Use all CPU cores\n",
    "    cv = skf,\n",
    "    random_state=42,\n",
    "    l1_ratios=(0,),  # Set to (0,) for L2 regularization only, avoiding the l1_ratios warning\n",
    "    use_legacy_attributes=True  # Set to True to silence the legacy attributes warning\n",
    ")\n",
    "\n",
    "model_bow = LogisticRegressionCV(\n",
    "    max_iter=1000, \n",
    "    Cs=20, \n",
    "    solver='saga', \n",
    "    n_jobs=-1, \n",
    "    cv = skf,\n",
    "    random_state=42,\n",
    "    l1_ratios=(0,),  # Same as above\n",
    "    use_legacy_attributes=True  # Same as above\n",
    ")\n",
    "\n",
    "model_tfidf_alt = MultinomialNB(\n",
    "    alpha=1.0,  # Laplace smoothing parameter\n",
    "    fit_prior=True,  # Learn class prior probabilities\n",
    "    class_prior=None  # Let the model learn class priors from the data\n",
    ")\n",
    "\n",
    "model_bow_alt = MultinomialNB(\n",
    "    alpha=1.0,\n",
    "    fit_prior=True,\n",
    "    class_prior=None\n",
    ")\n",
    "\n",
    "# Train TF-IDF model on full training set\n",
    "model_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = model_tfidf.predict(X_test_tfidf)\n",
    "print(\"TF-IDF Logistic Regression Test Results:\")\n",
    "print(classification_report(y_test, y_pred_tfidf))\n",
    "print(confusion_matrix(y_test, y_pred_tfidf))\n",
    "\n",
    "# Train alternative TF-IDF model (Naive Bayes) on full training set\n",
    "model_tfidf_alt.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf_alt = model_tfidf_alt.predict(X_test_tfidf)\n",
    "print(\"TF-IDF Naive Bayes Test Results:\")\n",
    "print(classification_report(y_test, y_pred_tfidf_alt))\n",
    "print(confusion_matrix(y_test, y_pred_tfidf_alt))\n",
    "\n",
    "# Train alternative BoW model (Naive Bayes) on full training set\n",
    "model_bow_alt.fit(X_train_bow, y_train)\n",
    "y_pred_bow_alt = model_bow_alt.predict(X_test_bow)\n",
    "print(\"BoW Naive Bayes Test Results:\")\n",
    "print(classification_report(y_test, y_pred_bow_alt))\n",
    "print(confusion_matrix(y_test, y_pred_bow_alt))\n",
    "\n",
    "# Train BoW model on full training set\n",
    "model_bow.fit(X_train_bow, y_train)\n",
    "y_pred_bow = model_bow.predict(X_test_bow)\n",
    "print(\"BoW Logistic Regression Test Results:\")\n",
    "print(classification_report(y_test, y_pred_bow))\n",
    "print(confusion_matrix(y_test, y_pred_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "945ea82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and vectorizers saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save trained models for deployment\n",
    "with open('sentiment_models.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'tfidf_model': model_tfidf,\n",
    "        'tfidf_model_alt': model_tfidf_alt,\n",
    "        'bow_model': model_bow,\n",
    "        'bow_model_alt': model_bow_alt,\n",
    "        'tfidf_vectorizer': tfidf_vectorizer,\n",
    "        'bow_vectorizer': bow_vectorizer\n",
    "    }, f)\n",
    "\n",
    "print(\"Models and vectorizers saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
